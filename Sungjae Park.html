<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sungjae Park</title>

  <meta name="author" content="Sungjae Park">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Sungjae Park</name>
                  </p>
                  <p>
                    Hi, I am a M.S. in Robotics student at Carnegie Mellon University, advised by Prof. <a
                    href="https://shubhtuls.github.io/">Shubham Tulsiani</a>.
                  </p>
                  <p>
                    Previously, I was a research intern in the Visual Computing lab at Seoul National University, advised by 
                    <a href="https://jhugestar.github.io/">Prof. Hanbyul Joo</a>. I also spent time in                     
                    <a href="https://www.clvrai.com/">CLVR lab</a> at KAIST,
                    advised by <a href="https://clvrai.com/web_lim/">Prof. Joseph J. Lim</a>.
                    I completed B.S. (Summa Cum Laude) in Mechanical Engineering and Mathematics at Seoul National
                    University.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:sungjae2@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                    <a href="data/SungjaePark_cv_20250102.pdf">CV</a> &nbsp/&nbsp
                    <!--  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <!--  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                    <a href="https://twitter.com/sungj1026">Twitter</a> &nbsp/&nbsp
                    <a href="https://github.com/RUreadyo">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/sungjae_circle.png"><img style="width:75%;max-width:75%" alt="profile photo"
                      src="images/sungjae_circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My research goal is to develop a robot with human-like abilities, including
                    <strong>physical capabilities</strong> for manipulation tasks, and <strong>cognitive
                      capabilities</strong> for intuitive understanding of the real world.
                  </p>
                  <p>
                    Specifically, I am interested in solving <strong>complex manipulation tasks</strong> (e.g.
                    dexterous, contact-rich, long-horizon tasks),
                    <br>
                    <strong>physical reasoning WITH interaction</strong> (e.g. experimenting with objects and inferring
                    properties with physical interaction), and
                    <br>
                    <strong>
                      physical reasoning FOR interaction</strong>(e.g. intuitive physics, leveraging object permanence
                    for efficient object retrieval).
                  </p>
                  <p>
                    * denotes equal contribution.
                  </p>


                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/mocaprobot.png" alt="critical" width="200" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://rureadyo.github.io/MocapRobot/">
                    <papertitle>Learning to Transfer Human Hand Skills for Robot Manipulations</papertitle>
                  </a>
                  <br>
                  <strong>Sungjae Park*</strong>, Seungho Lee*, Mingi Choi*, Jiye Lee, Jeonghwan Kim, Jisoo Kim, Hanbyul Joo.
                  <br>
                  CoRL X-Embodiment Workshop 2024
                  <br>
                  <a href="data/ICRA25__From_Mocap_to_Robot_Hand_FINAL.pdf">Paper</a> / <a
                    href="https://rureadyo.github.io/MocapRobot/">Website</a> 
                    <!-- <a href="https://github.com/droid-dataset/droid">Code</a> -->
                  <br>
                  <!-- <p>When humans are given with a complex manipulation task, such as putting a thread in a needle, they often fail in single shot. However, they can iteratively recover from the failure state and retry, completing the task in the end.
                We model such process as hierarchical reinforcement learning, where the high level policy determines whether to use task policy or call recovery. This improves suboptimal policy's success rate up to twice. </p>
              </p> -->


                  <!--<p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>-->
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/droid_teaser_animated.gif" alt="critical" width="200" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://droid-dataset.github.io/">
                    <papertitle>DROID: A Large-Scale In-the-Wild
                      Robot Manipulation Dataset</papertitle>
                  </a>
                  <br>
                  DROID Dataset Team
                  <br>
                  RSS 2024
                  <br>
                  <a href="https://arxiv.org/abs/2403.12945">Paper</a> / <a
                    href="https://droid-dataset.github.io/">Website</a> / <a
                    href="https://github.com/droid-dataset/droid">Code</a>
                  <br>
                  <!-- <p>When humans are given with a complex manipulation task, such as putting a thread in a needle, they often fail in single shot. However, they can iteratively recover from the failure state and retry, completing the task in the end.
                We model such process as hierarchical reinforcement learning, where the high level policy determines whether to use task policy or call recovery. This improves suboptimal policy's success rate up to twice. </p>
              </p> -->


                  <!--<p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>-->
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/teaser_compressed.gif" alt="critical" width="200" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://robotics-transformer-x.github.io/">
                    <papertitle>Open X-Embodiment: Robotic Learning Datasets and RT-X Models</papertitle>
                  </a>
                  <br>
                  Open X-Embodiment Collaboration
                  <br>
                  ICRA 2024 / <strong style="color:red">Best Conference Paper Award</strong>
                  <br>
                  <a href="https://arxiv.org/abs/2310.08864">Paper</a> / <a
                    href="https://robotics-transformer-x.github.io/">Website</a>
                  <br>
                  <!-- <p>When humans are given with a complex manipulation task, such as putting a thread in a needle, they often fail in single shot. However, they can iteratively recover from the failure state and retry, completing the task in the end.
                We model such process as hierarchical reinforcement learning, where the high level policy determines whether to use task policy or call recovery. This improves suboptimal policy's success rate up to twice. </p>
              </p> -->


                  <!--<p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>-->
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/ocp_example.png" alt="critical" width="200" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="data/Thesis__Object_Centric_Planning_for_Cross_Embodiment_Learning.pdf">
                    <papertitle>Efficient Cross-Embodiment Learning with Object-Centric Planner</papertitle>
                  </a>
                  <br>
                  <strong>Sungjae Park</strong>, <a href="https://clvrai.com/web_lim/">Joseph J. Lim</a>, <a
                    href="https://sites.google.com/robotics.snu.ac.kr/fcp/">Frank C. Park</a>
                  <br>
                  Bachelor's Thesis / <strong style="color: red;">Outstanding BS Thesis Presentation Award</strong>


                  <p>We learn object centric trajectory planner from different robot's demonstration for
                    cross-embodiment transfer. </p>
                  <!--<p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>-->
                </td>
              </tr>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Projects</heading>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/pgm_example.png" alt="pgm" width="160" height="160">
                    </td>
                    <td width="75%" valign="middle">
                      <a href="data/PGM(Sungjae Park).pdf">
                        <papertitle>Online Active Gaussian Process Motion Planning in Unknown Environments</papertitle>
                      </a>
                      <br>
                      <strong>Sungjae Park*</strong>, <a href="http://stumm.ca/">Hyelim Choi*</a>, <a
                        href="http://cosmo.nyu.edu/hogg/">Taekyun Kim*</a>
                      <br>
                      <em>Graduate Course Project (Probabilistic Graphical Models, Spring 2022)</em>
                      <br>
                      <p>We combine gaussian process motion planning with entropy-based information factor to perform
                        online active motion planning in unknown environments.</p>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/contrained_motion_planning_final.gif" alt="pgm" width="160" height="100">
                    </td>
                    <td width="75%" valign="middle">
                      <papertitle>Motion Planning under Constraint with Learned Reachable Manifold</papertitle>
                      <br>
                      <strong>Sungjae Park</strong>, Suhan Park
                      <p>
                        We learn reachable manifold of franka panda robot arm with block neural autoregressive flow as
                        in
                        <a href="https://ieeexplore.ieee.org/document/9561589" <papertitile> Kim et al.</papertitile>
                        </a>
                        , and perform contrained motion planning directly in the learned latent space.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/peg_insertion.gif" alt="pgm" width="160" height="160">
                    </td>
                    <td width="75%" valign="middle">
                      <papertitle>Vision Guided Peg Insertion</papertitle>
                      <br>
                      <strong>Sungjae Park*</strong>, Hosun Choi*, Hyunmoo Heo*
                      <p>We perform robust peg insertion with YOLO-v3 based hole/box detection model.</p>
                    </td>
                  </tr>
                  <!-- TODO: Add previous projects -->


                </tbody>
              </table>


              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td>
                      <heading>Teaching</heading>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/modern_robotics.jpeg" alt="modern_robotics" height="200" , width="150">
                    </td>
                    <td width="75%" valign="center">
                      <papertitle>Introduction to Robotics</papertitle>
                      <br>
                      <a href="http://hades.mech.northwestern.edu/index.php/Modern_Robotics">Student Instructor, Spring
                        2022</a>
                      <br>
                      <p></p>
                      <papertitle>College Physics 1, 2</papertitle>
                      <br>
                      Undergraduate Tutoring, Spring 2018, Fall 2018, Spring 2021, Fall 2021
                      <br>
                      <br>
                      <!--<a href="http://hades.mech.northwestern.edu/index.php/Modern_Robotics">Undergraduate Tutoring, Spring 2018, Fall 2018, Spring 2021, Fall 2021</a>-->
                      <papertitle>Linear Algebra</papertitle>
                      <br>Undergraduate Tutoring, Spring 2021
                      <!--<a href="http://hades.mech.northwestern.edu/index.php/Modern_Robotics">Undergraduate Tutoring, Spring 2021</a>-->
                      <br>
                      <p></p>
                    </td>

                  </tr>



                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>

                    </tbody>
                  </table>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">

                        <br>
                        Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>